---
---

# Using Datasets

This is an introduction to how to evaluate models on specific datasets.

Please refer to [Types of Datasets](../../background/dataset-types) to understand the concept of datasets.

We provide only one implementation that is as correct as possible, but we do not guarantee that the various logics of the dataset are exactly the same as the original.

## [HumanEval](./humaneval)

Includes:

- HumanEvalPython

## [AutoEval](./autoeval)

Includes:

- LeetCode (a small subset)

## [CommonOJ](./common-oj)

Includes:

- CodeContests

There are also some datasets that are being organized and tested, which will be released gradually:

- MultiPL-E HumanEval
- Shadow Humaneval
- CodeContests
- MBPP
- MBXP
- MHPP
- CRUXEval
- NaturalCodeBench
- PAL-Math
- verilog-eval
- miniF2F
